{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76b9fc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83a26808",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\".\").absolute().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c3179ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GestureDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        self.initialize()\n",
    "    \n",
    "    def initialize(self):\n",
    "        gestures = list(sorted((Path(\".\").absolute().parent / \"data\").iterdir()))\n",
    "        for y, gesture in enumerate(gestures):\n",
    "            for file in gesture.glob(\"*.npy\"):\n",
    "                self.X.append(file)\n",
    "                self.y.append(y)\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = np.load(str(self.X[idx])).astype(np.float32)\n",
    "        X = torch.from_numpy(X)\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.long)\n",
    "        \n",
    "        return X, y\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68faa11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = GestureDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67d0c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split, test_split = random_split(ds, [0.7, 0.3], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "802586f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_split, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_split, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a8306e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f76c208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GestureClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear_stack1 = nn.Sequential(\n",
    "            nn.Linear(in_features=42, out_features=20),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(.2)\n",
    "        )\n",
    "        \n",
    "        self.linear_stack2 = nn.Sequential(\n",
    "            nn.Linear(in_features=20, out_features=10),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(.4)\n",
    "        )\n",
    "        \n",
    "        self.output = nn.Linear(in_features=10, out_features=n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear_stack1(x)\n",
    "        x = self.linear_stack2(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09530130",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_dl, test_dl, epochs=1000, patience=10):\n",
    "        self.model = model\n",
    "        self.train_dl = train_dl\n",
    "        self.test_dl = test_dl\n",
    "        self.epochs = epochs\n",
    "        self.patience = 10\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.optimzer = torch.optim.Adam(model.parameters())\n",
    "        \n",
    "        self.best_acc = 0\n",
    "        self.current_patience = patience\n",
    "        self.best_model = None\n",
    "        \n",
    "    def train(self):\n",
    "        for t in range(self.epochs):\n",
    "            print(f\"Epoch: {t+1}\")\n",
    "            self.train_loop()\n",
    "            self.test_loop()\n",
    "            if self.current_patience == 0:\n",
    "                self.model.state_dict = self.best_model\n",
    "                print(\"Patience broken\")\n",
    "                break\n",
    "        print(\"Done\")\n",
    "        torch.save(self.model.state_dict(),  str(base_path / \"models\" / \"gesture_clf.pth\"))\n",
    "        \n",
    "    def train_loop(self):\n",
    "        size = len(self.train_dl.dataset)\n",
    "        for batch, (X, y) in enumerate(self.train_dl):\n",
    "            pred = self.model(X)\n",
    "            loss = self.loss_fn(pred, y)\n",
    "            \n",
    "            self.optimzer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimzer.step()\n",
    "            \n",
    "            if batch % 10== 0:\n",
    "                loss, current = loss.item(), batch * len(X)\n",
    "                print(f\"loss: {loss} [{current}/{size}]\")\n",
    "                \n",
    "    def test_loop(self):\n",
    "        num_batches = len(self.test_dl)\n",
    "        test_loss, correct = 0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X, y in self.test_dl:\n",
    "                pred = self.model(X)\n",
    "                test_loss += self.loss_fn(pred, y).item()\n",
    "                correct += (pred.argmax(1) == y).type(torch.float).sum().item() / self.test_dl.batch_size\n",
    "                \n",
    "        test_loss /= num_batches\n",
    "        correct /= num_batches\n",
    "        print(f\"Test Acc: {correct * 100}%, Avg loss: {test_loss}\")\n",
    "        \n",
    "        if correct > self.best_acc:\n",
    "            self.best_acc = correct\n",
    "            self.best_model = self.model.state_dict\n",
    "            self.current_patience = self.patience\n",
    "        else:\n",
    "            self.current_patience -= 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac028df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GestureClassifier(3)\n",
    "trainer = Trainer(model, train_dataloader, test_dataloader, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b7745d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "loss: 1.1184861660003662 [0/1567]\n",
      "loss: 1.0942144393920898 [320/1567]\n",
      "loss: 1.084151029586792 [640/1567]\n",
      "loss: 1.0800232887268066 [960/1567]\n",
      "loss: 1.0501691102981567 [1280/1567]\n",
      "Test Acc: 45.535714285714285%, Avg loss: 1.0690373125530424\n",
      "Epoch: 2\n",
      "loss: 1.0976680517196655 [0/1567]\n",
      "loss: 1.0522868633270264 [320/1567]\n",
      "loss: 1.0519143342971802 [640/1567]\n",
      "loss: 1.0148811340332031 [960/1567]\n",
      "loss: 0.9660263061523438 [1280/1567]\n",
      "Test Acc: 49.25595238095239%, Avg loss: 1.041172879082816\n",
      "Epoch: 3\n",
      "loss: 1.0097383260726929 [0/1567]\n",
      "loss: 0.9801128506660461 [320/1567]\n",
      "loss: 1.0211849212646484 [640/1567]\n",
      "loss: 1.0758389234542847 [960/1567]\n",
      "loss: 0.9867303967475891 [1280/1567]\n",
      "Test Acc: 56.25%, Avg loss: 0.9822352088633037\n",
      "Epoch: 4\n",
      "loss: 1.0370632410049438 [0/1567]\n",
      "loss: 0.9014425873756409 [320/1567]\n",
      "loss: 0.991741955280304 [640/1567]\n",
      "loss: 0.9720467925071716 [960/1567]\n",
      "loss: 0.8719087243080139 [1280/1567]\n",
      "Test Acc: 61.16071428571429%, Avg loss: 0.8994372515451341\n",
      "Epoch: 5\n",
      "loss: 0.9275554418563843 [0/1567]\n",
      "loss: 0.8809625506401062 [320/1567]\n",
      "loss: 0.8432440161705017 [640/1567]\n",
      "loss: 0.8221247792243958 [960/1567]\n",
      "loss: 0.7215937972068787 [1280/1567]\n",
      "Test Acc: 69.19642857142857%, Avg loss: 0.7960676394757771\n",
      "Epoch: 6\n",
      "loss: 0.8470544219017029 [0/1567]\n",
      "loss: 0.8781934976577759 [320/1567]\n",
      "loss: 0.6720492243766785 [640/1567]\n",
      "loss: 0.8953975439071655 [960/1567]\n",
      "loss: 0.7611468434333801 [1280/1567]\n",
      "Test Acc: 70.53571428571429%, Avg loss: 0.7150442117736453\n",
      "Epoch: 7\n",
      "loss: 0.7358577251434326 [0/1567]\n",
      "loss: 0.6796894073486328 [320/1567]\n",
      "loss: 0.6944695711135864 [640/1567]\n",
      "loss: 0.6596093773841858 [960/1567]\n",
      "loss: 0.6425880789756775 [1280/1567]\n",
      "Test Acc: 74.55357142857143%, Avg loss: 0.6129458681458518\n",
      "Epoch: 8\n",
      "loss: 0.5876624584197998 [0/1567]\n",
      "loss: 0.5408092737197876 [320/1567]\n",
      "loss: 0.485952228307724 [640/1567]\n",
      "loss: 0.6585832238197327 [960/1567]\n",
      "loss: 0.6995623111724854 [1280/1567]\n",
      "Test Acc: 74.40476190476191%, Avg loss: 0.5790529761995588\n",
      "Epoch: 9\n",
      "loss: 0.48888933658599854 [0/1567]\n",
      "loss: 0.6331549882888794 [320/1567]\n",
      "loss: 0.7048013806343079 [640/1567]\n",
      "loss: 0.4992867112159729 [960/1567]\n",
      "loss: 0.5645270943641663 [1280/1567]\n",
      "Test Acc: 77.38095238095238%, Avg loss: 0.5243765207983199\n",
      "Epoch: 10\n",
      "loss: 0.6014323234558105 [0/1567]\n",
      "loss: 0.5242059826850891 [320/1567]\n",
      "loss: 0.4878377914428711 [640/1567]\n",
      "loss: 0.4406120181083679 [960/1567]\n",
      "loss: 0.5439419150352478 [1280/1567]\n",
      "Test Acc: 77.52976190476191%, Avg loss: 0.48660701300416676\n",
      "Epoch: 11\n",
      "loss: 0.42513561248779297 [0/1567]\n",
      "loss: 0.5672062635421753 [320/1567]\n",
      "loss: 0.5336180925369263 [640/1567]\n",
      "loss: 0.4821426570415497 [960/1567]\n",
      "loss: 0.4942079484462738 [1280/1567]\n",
      "Test Acc: 80.65476190476191%, Avg loss: 0.463308348542168\n",
      "Epoch: 12\n",
      "loss: 0.4641338884830475 [0/1567]\n",
      "loss: 0.6438357830047607 [320/1567]\n",
      "loss: 0.4909512996673584 [640/1567]\n",
      "loss: 0.4777114689350128 [960/1567]\n",
      "loss: 0.46163249015808105 [1280/1567]\n",
      "Test Acc: 80.95238095238095%, Avg loss: 0.44024940934919177\n",
      "Epoch: 13\n",
      "loss: 0.4151034653186798 [0/1567]\n",
      "loss: 0.3544521927833557 [320/1567]\n",
      "loss: 0.5424066781997681 [640/1567]\n",
      "loss: 0.3298119008541107 [960/1567]\n",
      "loss: 0.5011066794395447 [1280/1567]\n",
      "Test Acc: 83.92857142857143%, Avg loss: 0.4245875389093444\n",
      "Epoch: 14\n",
      "loss: 0.28241944313049316 [0/1567]\n",
      "loss: 0.37026116251945496 [320/1567]\n",
      "loss: 0.35630518198013306 [640/1567]\n",
      "loss: 0.4520920217037201 [960/1567]\n",
      "loss: 0.3929656744003296 [1280/1567]\n",
      "Test Acc: 86.16071428571429%, Avg loss: 0.3968574560823895\n",
      "Epoch: 15\n",
      "loss: 0.36142513155937195 [0/1567]\n",
      "loss: 0.35690608620643616 [320/1567]\n",
      "loss: 0.5484139919281006 [640/1567]\n",
      "loss: 0.3194828927516937 [960/1567]\n",
      "loss: 0.48517894744873047 [1280/1567]\n",
      "Test Acc: 87.20238095238095%, Avg loss: 0.37138745720897404\n",
      "Epoch: 16\n",
      "loss: 0.44995880126953125 [0/1567]\n",
      "loss: 0.3818861246109009 [320/1567]\n",
      "loss: 0.24668064713478088 [640/1567]\n",
      "loss: 0.3740299940109253 [960/1567]\n",
      "loss: 0.23799516260623932 [1280/1567]\n",
      "Test Acc: 86.60714285714286%, Avg loss: 0.37040605963695616\n",
      "Epoch: 17\n",
      "loss: 0.30036109685897827 [0/1567]\n",
      "loss: 0.37429267168045044 [320/1567]\n",
      "loss: 0.3988976776599884 [640/1567]\n",
      "loss: 0.2941284477710724 [960/1567]\n",
      "loss: 0.3256864547729492 [1280/1567]\n",
      "Test Acc: 87.5%, Avg loss: 0.34557113477161955\n",
      "Epoch: 18\n",
      "loss: 0.3641965091228485 [0/1567]\n",
      "loss: 0.37936872243881226 [320/1567]\n",
      "loss: 0.3113323748111725 [640/1567]\n",
      "loss: 0.2835603654384613 [960/1567]\n",
      "loss: 0.2834973633289337 [1280/1567]\n",
      "Test Acc: 87.20238095238095%, Avg loss: 0.3453708700835705\n",
      "Epoch: 19\n",
      "loss: 0.2868051826953888 [0/1567]\n",
      "loss: 0.36466360092163086 [320/1567]\n",
      "loss: 0.3070054054260254 [640/1567]\n",
      "loss: 0.36609238386154175 [960/1567]\n",
      "loss: 0.2816920876502991 [1280/1567]\n",
      "Test Acc: 87.79761904761905%, Avg loss: 0.31135569761196774\n",
      "Epoch: 20\n",
      "loss: 0.28991836309432983 [0/1567]\n",
      "loss: 0.37066683173179626 [320/1567]\n",
      "loss: 0.3030540347099304 [640/1567]\n",
      "loss: 0.30099180340766907 [960/1567]\n",
      "loss: 0.36453840136528015 [1280/1567]\n",
      "Test Acc: 88.83928571428571%, Avg loss: 0.319662371384246\n",
      "Epoch: 21\n",
      "loss: 0.27899378538131714 [0/1567]\n",
      "loss: 0.37473124265670776 [320/1567]\n",
      "loss: 0.3638455271720886 [640/1567]\n",
      "loss: 0.20661026239395142 [960/1567]\n",
      "loss: 0.326605886220932 [1280/1567]\n",
      "Test Acc: 88.39285714285714%, Avg loss: 0.29866359755396843\n",
      "Epoch: 22\n",
      "loss: 0.2922675907611847 [0/1567]\n",
      "loss: 0.41833528876304626 [320/1567]\n",
      "loss: 0.32508018612861633 [640/1567]\n",
      "loss: 0.26539018750190735 [960/1567]\n",
      "loss: 0.28409650921821594 [1280/1567]\n",
      "Test Acc: 89.88095238095238%, Avg loss: 0.2829532191334736\n",
      "Epoch: 23\n",
      "loss: 0.22620601952075958 [0/1567]\n",
      "loss: 0.2788078486919403 [320/1567]\n",
      "loss: 0.3858414590358734 [640/1567]\n",
      "loss: 0.2555861473083496 [960/1567]\n",
      "loss: 0.19140022993087769 [1280/1567]\n",
      "Test Acc: 90.32738095238095%, Avg loss: 0.27114571382602054\n",
      "Epoch: 24\n",
      "loss: 0.26030755043029785 [0/1567]\n",
      "loss: 0.26513898372650146 [320/1567]\n",
      "loss: 0.3051113486289978 [640/1567]\n",
      "loss: 0.3059965968132019 [960/1567]\n",
      "loss: 0.2109728902578354 [1280/1567]\n",
      "Test Acc: 91.36904761904762%, Avg loss: 0.2665827652173383\n",
      "Epoch: 25\n",
      "loss: 0.2511003613471985 [0/1567]\n",
      "loss: 0.29386383295059204 [320/1567]\n",
      "loss: 0.2399003654718399 [640/1567]\n",
      "loss: 0.2275722771883011 [960/1567]\n",
      "loss: 0.23254647850990295 [1280/1567]\n",
      "Test Acc: 90.625%, Avg loss: 0.24496130450140863\n",
      "Epoch: 26\n",
      "loss: 0.27178633213043213 [0/1567]\n",
      "loss: 0.36479952931404114 [320/1567]\n",
      "loss: 0.27165648341178894 [640/1567]\n",
      "loss: 0.3505137264728546 [960/1567]\n",
      "loss: 0.1699216067790985 [1280/1567]\n",
      "Test Acc: 92.26190476190477%, Avg loss: 0.22747395737540155\n",
      "Epoch: 27\n",
      "loss: 0.12684938311576843 [0/1567]\n",
      "loss: 0.3125961422920227 [320/1567]\n",
      "loss: 0.18895502388477325 [640/1567]\n",
      "loss: 0.19260355830192566 [960/1567]\n",
      "loss: 0.21619686484336853 [1280/1567]\n",
      "Test Acc: 91.51785714285714%, Avg loss: 0.2296778623546873\n",
      "Epoch: 28\n",
      "loss: 0.09062124043703079 [0/1567]\n",
      "loss: 0.20969589054584503 [320/1567]\n",
      "loss: 0.32395750284194946 [640/1567]\n",
      "loss: 0.2562636137008667 [960/1567]\n",
      "loss: 0.2336098998785019 [1280/1567]\n",
      "Test Acc: 91.36904761904762%, Avg loss: 0.2405748814344406\n",
      "Epoch: 29\n",
      "loss: 0.2548629939556122 [0/1567]\n",
      "loss: 0.18765324354171753 [320/1567]\n",
      "loss: 0.29741567373275757 [640/1567]\n",
      "loss: 0.1785559058189392 [960/1567]\n",
      "loss: 0.17583321034908295 [1280/1567]\n",
      "Test Acc: 91.22023809523809%, Avg loss: 0.22038323396728152\n",
      "Epoch: 30\n",
      "loss: 0.12661783397197723 [0/1567]\n",
      "loss: 0.14384597539901733 [320/1567]\n",
      "loss: 0.2815360724925995 [640/1567]\n",
      "loss: 0.16456477344036102 [960/1567]\n",
      "loss: 0.3114219009876251 [1280/1567]\n",
      "Test Acc: 91.66666666666666%, Avg loss: 0.2198884714217413\n",
      "Epoch: 31\n",
      "loss: 0.17237839102745056 [0/1567]\n",
      "loss: 0.4033794701099396 [320/1567]\n",
      "loss: 0.11657892167568207 [640/1567]\n",
      "loss: 0.20331686735153198 [960/1567]\n",
      "loss: 0.21626392006874084 [1280/1567]\n",
      "Test Acc: 92.41071428571429%, Avg loss: 0.22449851843218008\n",
      "Epoch: 32\n",
      "loss: 0.17568336427211761 [0/1567]\n",
      "loss: 0.23241420090198517 [320/1567]\n",
      "loss: 0.15386101603507996 [640/1567]\n",
      "loss: 0.18225879967212677 [960/1567]\n",
      "loss: 0.17867840826511383 [1280/1567]\n",
      "Test Acc: 93.45238095238095%, Avg loss: 0.18002137887690747\n",
      "Epoch: 33\n",
      "loss: 0.060879744589328766 [0/1567]\n",
      "loss: 0.16119152307510376 [320/1567]\n",
      "loss: 0.250343918800354 [640/1567]\n",
      "loss: 0.3221851885318756 [960/1567]\n",
      "loss: 0.22786836326122284 [1280/1567]\n",
      "Test Acc: 93.15476190476191%, Avg loss: 0.20198413277310984\n",
      "Epoch: 34\n",
      "loss: 0.1555943489074707 [0/1567]\n",
      "loss: 0.21803595125675201 [320/1567]\n",
      "loss: 0.18594762682914734 [640/1567]\n",
      "loss: 0.2327958643436432 [960/1567]\n",
      "loss: 0.2626838684082031 [1280/1567]\n",
      "Test Acc: 92.41071428571429%, Avg loss: 0.18781871224443117\n",
      "Epoch: 35\n",
      "loss: 0.12035692483186722 [0/1567]\n",
      "loss: 0.13384240865707397 [320/1567]\n",
      "loss: 0.3120139539241791 [640/1567]\n",
      "loss: 0.27367404103279114 [960/1567]\n",
      "loss: 0.21829478442668915 [1280/1567]\n",
      "Test Acc: 93.00595238095238%, Avg loss: 0.1825896595560369\n",
      "Epoch: 36\n",
      "loss: 0.26331594586372375 [0/1567]\n",
      "loss: 0.2383432388305664 [320/1567]\n",
      "loss: 0.19177411496639252 [640/1567]\n",
      "loss: 0.10582388192415237 [960/1567]\n",
      "loss: 0.2390710562467575 [1280/1567]\n",
      "Test Acc: 93.30357142857143%, Avg loss: 0.16877501129749276\n",
      "Epoch: 37\n",
      "loss: 0.2381800413131714 [0/1567]\n",
      "loss: 0.21255026757717133 [320/1567]\n",
      "loss: 0.2737436592578888 [640/1567]\n",
      "loss: 0.3743686079978943 [960/1567]\n",
      "loss: 0.13677072525024414 [1280/1567]\n",
      "Test Acc: 92.70833333333334%, Avg loss: 0.1933558095423948\n",
      "Epoch: 38\n",
      "loss: 0.1778104305267334 [0/1567]\n",
      "loss: 0.14939440786838531 [320/1567]\n",
      "loss: 0.12179528176784515 [640/1567]\n",
      "loss: 0.22459569573402405 [960/1567]\n",
      "loss: 0.4025666117668152 [1280/1567]\n",
      "Test Acc: 91.96428571428571%, Avg loss: 0.18774043076804706\n",
      "Epoch: 39\n",
      "loss: 0.18123801052570343 [0/1567]\n",
      "loss: 0.19092196226119995 [320/1567]\n",
      "loss: 0.20978312194347382 [640/1567]\n",
      "loss: 0.15503357350826263 [960/1567]\n",
      "loss: 0.17695535719394684 [1280/1567]\n",
      "Test Acc: 92.55952380952381%, Avg loss: 0.18360498166155248\n",
      "Epoch: 40\n",
      "loss: 0.10038046538829803 [0/1567]\n",
      "loss: 0.2303292453289032 [320/1567]\n",
      "loss: 0.21405258774757385 [640/1567]\n",
      "loss: 0.16528615355491638 [960/1567]\n",
      "loss: 0.2616153061389923 [1280/1567]\n",
      "Test Acc: 92.85714285714286%, Avg loss: 0.18073735306305544\n",
      "Epoch: 41\n",
      "loss: 0.11717058718204498 [0/1567]\n",
      "loss: 0.33134913444519043 [320/1567]\n",
      "loss: 0.15225210785865784 [640/1567]\n",
      "loss: 0.11472510546445847 [960/1567]\n",
      "loss: 0.15704959630966187 [1280/1567]\n",
      "Test Acc: 92.55952380952381%, Avg loss: 0.175514053819435\n",
      "Epoch: 42\n",
      "loss: 0.14130982756614685 [0/1567]\n",
      "loss: 0.15577992796897888 [320/1567]\n",
      "loss: 0.0579083114862442 [640/1567]\n",
      "loss: 0.09178534150123596 [960/1567]\n",
      "loss: 0.1606903374195099 [1280/1567]\n",
      "Test Acc: 93.15476190476191%, Avg loss: 0.15988411612453915\n",
      "Patience broken\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "63061e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "242ebc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 42])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "15e5dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(16, 64, 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(2688, 1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        print(x.size())\n",
    "#         x = torch.flatten(x)\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bb987d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ConvClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e1c3fa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(16, 1, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b012351b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 42])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7ea72c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64, 42])\n"
     ]
    }
   ],
   "source": [
    "out = m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f09e72b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0376,  0.0040, -0.0273,  0.0151, -0.0162,  0.0375,  0.0184,  0.0556,\n",
       "        -0.0143, -0.0587], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "73d3f7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ba985a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.2438, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(out, torch.randn(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f7645e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.randn(1, 10)\n",
    "t2 = torch.randn(1, 10)\n",
    "t3 = torch.stack((t1, t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "662a6115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 10])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bf339add",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = nn.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "078c071a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten(t3).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b418a336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3892, -0.8036, -2.2099, -0.6902,  1.9779,  2.4583, -0.4430, -1.1128,\n",
       "          0.7266,  1.5586]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fb7b8672",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(base_path / \"data\" / \"point_up\" / \"00000.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "09086c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46355143, 0.98830217, 0.50423163, 0.97798246, 0.53948539,\n",
       "       0.90498883, 0.54393858, 0.83076483, 0.5424158 , 0.76208138,\n",
       "       0.51942861, 0.78046501, 0.52059108, 0.69570863, 0.51853007,\n",
       "       0.62922424, 0.5154928 , 0.57830215, 0.47013804, 0.76820189,\n",
       "       0.47058395, 0.72023898, 0.48166522, 0.7768656 , 0.4931978 ,\n",
       "       0.82481194, 0.42324179, 0.78242403, 0.43131328, 0.80025256,\n",
       "       0.4477661 , 0.88284487, 0.46112165, 0.9374404 , 0.37857261,\n",
       "       0.81729281, 0.39336514, 0.85285443, 0.41415969, 0.91794497,\n",
       "       0.43098775, 0.9552092 ])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184ab5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
